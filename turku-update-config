#!/usr/bin/python

from __future__ import print_function
import uuid
import string
import random
import json
import os
import copy
import subprocess
import sys
import platform

CONFIG_D = '/etc/turku-agent/config.d'
SOURCES_D = '/etc/turku-agent/sources.d'
SOURCES_SECRETS_D = '/etc/turku-agent/sources_secrets.d'
SSH_PRIVATE_KEY = '/etc/turku-agent/id_rsa'
SSH_PUBLIC_KEY = '/etc/turku-agent/id_rsa.pub'
RSYNCD_CONF = '/etc/turku-agent/rsyncd.conf'
RSYNCD_SECRETS = '/etc/turku-agent/rsyncd.secrets'
VAR_DIR = '/var/lib/turku-agent'


def json_dump_p(obj, f):
    """Calls json.dump with standard (pretty) formatting"""
    return json.dump(obj, f, sort_keys=True, indent=4, separators=(',', ': '))


def json_dumps_p(obj):
    """Calls json.dumps with standard (pretty) formatting"""
    return json.dumps(obj, sort_keys=True, indent=4, separators=(',', ': '))


def dict_merge(s, m):
    """Recursively merge one dict into another."""
    if not isinstance(m, dict):
        return m
    out = copy.deepcopy(s)
    for k, v in m.items():
        if k in out and isinstance(out[k], dict):
            out[k] = dict_merge(out[k], v)
        else:
            out[k] = copy.deepcopy(v)
    return out


def check_directories():
    for d in (CONFIG_D, SOURCES_D, VAR_DIR):
        if not os.path.isdir(d):
            os.makedirs(d)
    for d in (SOURCES_SECRETS_D,):
        if not os.path.isdir(d):
            os.makedirs(d)
            os.chmod(d, 0o700)
    for f in (SSH_PRIVATE_KEY, SSH_PUBLIC_KEY, RSYNCD_CONF, RSYNCD_SECRETS):
        d = os.path.dirname(f)
        if not os.path.isdir(d):
            os.makedirs(d)


def parse_config():
    built_config = {
        'sources': {}
    }

    # Merge in config.d/*.json to the root level
    config_files = [os.path.join(CONFIG_D, fn) for fn in os.listdir(CONFIG_D) if fn.endswith('.json') and os.path.isfile(os.path.join(CONFIG_D, fn)) and os.access(os.path.join(CONFIG_D, fn), os.R_OK)]
    config_files.sort()
    for file in config_files:
        with open(file) as f:
            j = json.load(f)
        built_config = dict_merge(built_config, j)

    # Validate the unit name
    if not 'unit_name' in built_config:
        built_config['unit_name'] = platform.node()
        # If this isn't in the on-disk config, don't write it; just
        # generate it every time

    # Validate the machine UUID/secret
    write_uuid_data = False
    if not 'machine_uuid' in built_config:
        built_config['machine_uuid'] = str(uuid.uuid4())
        write_uuid_data = True
    if not 'machine_secret' in built_config:
        built_config['machine_secret'] = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(30))
        write_uuid_data = True
    # Write out the machine UUID/secret if needed
    if write_uuid_data:
        with open(os.path.join(CONFIG_D, '10-machine_uuid.json'), 'w') as f:
            os.chmod(os.path.join(CONFIG_D, '10-machine_uuid.json'), 0o600)
            json_dump_p({'machine_uuid': built_config['machine_uuid'], 'machine_secret': built_config['machine_secret']}, f)

    # Generate the SSH keypair if it doesn't exist
    if not os.path.isfile(SSH_PUBLIC_KEY):
        subprocess.check_call(['ssh-keygen', '-t', 'rsa', '-N', '', '-C', 'turku', '-f', SSH_PRIVATE_KEY])

    # Pull the SSH public key
    with open(SSH_PUBLIC_KEY) as f:
        built_config['ssh_public_key'] = f.read().rstrip()

    # Merge in sources.d/*.json to the sources dict
    sources_files = [os.path.join(SOURCES_D, fn) for fn in os.listdir(SOURCES_D) if fn.endswith('.json') and os.path.isfile(os.path.join(SOURCES_D, fn)) and os.access(os.path.join(SOURCES_D, fn), os.R_OK)]
    sources_files.sort()
    for file in sources_files:
        with open(file) as f:
            j = json.load(f)
        for s in j.keys():
            # Ignore incomplete source entries
            if not 'path' in j[s]:
                print('WARNING: Path not found for "%s", not using.' % s, file=sys.stderr)
                del j[s]
        built_config = dict_merge(built_config, {'sources': j})

    for s in built_config['sources']:
        # Check for missing usernames/passwords
        if not ('username' in built_config['sources'][s] or 'password' in built_config['sources'][s]):
            # If they're in sources_secrets.d, use them
            if os.path.isfile(os.path.join(SOURCES_SECRETS_D, s + '.json')):
                with open(os.path.join(SOURCES_SECRETS_D, s + '.json')) as f:
                    j = json.load(f)
                built_config = dict_merge(built_config, {'sources': {s: j}})
        # Check again and generate sources_secrets.d if still not found
        if not ('username' in built_config['sources'][s] or 'password' in built_config['sources'][s]):
            if not 'username' in built_config['sources'][s]:
                built_config['sources'][s]['username'] = str(uuid.uuid4())
            if not 'password' in built_config['sources'][s]:
                built_config['sources'][s]['password'] = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(30))
            with open(os.path.join(SOURCES_SECRETS_D, s + '.json'), 'w') as f:
                json_dump_p({'username': built_config['sources'][s]['username'], 'password': built_config['sources'][s]['password']}, f)

    #print(json_dumps_p(built_config))

    return(built_config)


def write_conf_files(built_config):
    # Build rsyncd.conf
    built_rsyncd_conf = 'address = 127.0.0.1\nport = 27873\nlog file = /dev/stdout\nuid = root\ngid = root\nlist = false\n\n'
    rsyncd_secrets = []
    for s in built_config['sources']:
        sd = built_config['sources'][s]
        rsyncd_secrets.append((sd['username'], sd['password']))
        built_rsyncd_conf += '[%s]\n    path = %s\n    auth users = %s\n    secrets_file = %s\n    read only = true\n\n' % (s, sd['path'], sd['username'], RSYNCD_SECRETS)
    with open(RSYNCD_CONF, 'w') as f:
        f.write(built_rsyncd_conf)

    #print(built_rsyncd_conf)

    # Build rsyncd.secrets
    built_rsyncd_secrets = ''
    for (username, password) in rsyncd_secrets:
        built_rsyncd_secrets += username + ':' + password + '\n'
    with open(RSYNCD_SECRETS, 'w') as f:
        os.chmod(RSYNCD_SECRETS, 0o600)
        f.write(built_rsyncd_secrets)

    #print(built_rsyncd_secrets)


def restart_services():
    # Restart rsyncd
    if not subprocess.call(['service', 'turku-agent-rsyncd', 'restart']) == 0:
        subprocess.check_call(['service', 'turku-agent-rsyncd', 'start'])


def send_config(built_config):
    if not 'api_url' in built_config:
        return

    import httplib
    import urlparse

    # Send the completed config to the API server
    url = urlparse.urlparse(built_config['api_url'])
    if url.scheme == 'https':
        h = httplib.HTTPSConnection(url.netloc, timeout=5)
    else:
        h = httplib.HTTPConnection(url.netloc, timeout=5)
    dumped_json = json.dumps(built_config)
    h.putrequest('POST', '%s/update_config' % url.path)
    h.putheader('Content-Type', 'application/json')
    h.putheader('Content-Length', len(dumped_json))
    h.putheader('Accept', 'application/json')
    h.endheaders()
    h.send(dumped_json)

    # Read/validate the response
    res = h.getresponse()
    if not res.status == httplib.OK:
        return
    if not res.getheader('content-type') == 'application/json':
        return
    try:
        server_config = json.load(res)
    except ValueError:
        return

    # Write the response
    with open(os.path.join(VAR_DIR, 'server_config.json'), 'w') as f:
        os.chmod(os.path.join(VAR_DIR, 'server_config.json'), 0o600)
        json_dump_p(server_config, f)


def main(argv):
    check_directories()
    built_config = parse_config()
    write_conf_files(built_config)
    send_config(built_config)
    restart_services()


if __name__ == '__main__':
    sys.exit(main(sys.argv[1:]))
